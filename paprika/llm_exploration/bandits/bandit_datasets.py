import os
from typing import Dict, List, Optional, Tuple, Union
from transformers import AutoTokenizer
import numpy as np
import torch

from llm_exploration.common.tokenizer_separators import TokenizerSeparators
from llm_exploration.llm_finetuning.sft_dataset import MultiturnSFTDataset
from llm_exploration.llm_finetuning.rwr_dataset import MultiturnRWRDataset
from llm_exploration.utils.data_utils import read_json


def get_bandit_dataset(
    trainer_type: str,
    data_dir: str,
    tokenizer: AutoTokenizer,
    tokenizer_separator: TokenizerSeparators,
    ignore_token_id: int,
    num_samples: Optional[int] = None,
    rwr_gamma: float = 0.9,
    rwr_min_reward: float = 0.0,
) -> torch.utils.data.Dataset:
    """
    Helper function to load Bandit datasets.

    Input:
        trainer_type (str):
            The type of the trainer for this dataset.
            Supported choices: "SFT", "GEM", "OfflineRWR"

        data_dir (str):
            directory where the json files containing
            train trajectories are located.

        tokenizer (transformers.AutoTokenizer):
            the tokenizer for the particular model.

        tokenizer_separator (TokenizerSeparators):
            tokenizer separator used for this model.

        ignore_token_id (int):
            The token that should be ignored from loss calculations.

        num_samples (int):
            Number of samples to use from the entire list
            Default: None, in which case the entire list of datapoints is used.

        gamma (float):
            Discount factor for the typical RL problem.
            Default: 0.9

        min_reward (float):
            The minimum reward to give for every turn,
            if reward is below this, we clip it.
            Default: 0.0
    """
    if trainer_type in ["SFT", "GEM"]:
        return BanditSFTDataset(
            data_dir=data_dir,
            tokenizer=tokenizer,
            tokenizer_separator=tokenizer_separator,
            ignore_token_id=ignore_token_id,
            num_samples=num_samples,
        )
    elif trainer_type == "OfflineRWR":
        return BanditRWRDataset(
            data_dir=data_dir,
            tokenizer=tokenizer,
            tokenizer_separator=tokenizer_separator,
            ignore_token_id=ignore_token_id,
            gamma=rwr_gamma,
            min_reward=rwr_min_reward,
            num_samples=num_samples,
        )
    else:
        raise ValueError(f"Given trainer type {trainer_type} not supported.")


class BanditSFTDataset(MultiturnSFTDataset):
    """
    A special inherited class from Multi-turn SFT datasets.
    This class loads bandit trajectories in text format,
    generated by either LLMs ("gpt-4o-mini") or bandit algorithms (UCB).
    """

    def __init__(
        self,
        data_dir: str,
        tokenizer: AutoTokenizer,
        tokenizer_separator: TokenizerSeparators,
        ignore_token_id: int,
        num_samples: Optional[int] = None,
    ):
        """
        Input:
            data_dir (str):
                Directory where the bandit trajectories
                are stored as json files.

                This expects the data files in a certain format.

            tokenizer (Tokenizer):
                tokenizer for the model to be trained.

            tokenizer_separator (TokenizerSeparators):
                The tokenizer separator for assistant/user special tokens.

            ignore_token_id (int):
                The token that should be ignored.

            num_samples (int):
                Number of samples to use from the entire list
                Default: None, in which case the entire list of datapoints is used.
        """
        bandit_trajectories, _ = load_trajectories(data_dir=data_dir)

        super().__init__(
            conversations=bandit_trajectories,
            tokenizer=tokenizer,
            tokenizer_separator=tokenizer_separator,
            ignore_token_id=ignore_token_id,
        )

        if num_samples is None:
            self.indices = [i for i in range(super().__len__())]
        else:
            if not isinstance(num_samples, int) or num_samples <= 0:
                raise ValueError(f"Given num samples {num_samples} is not valid.")

            self.indices = np.random.choice(
                a=super().__len__(),
                size=num_samples,
                replace=(num_samples > super().__len__()),
            ).tolist()

    def __len__(self) -> int:
        """
        Returns the number of datapoints in the dataset.

        Input:
            None

        Output:
            length: Number of datapoints in the dataset
        """
        return len(self.indices)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        Returns the i-th datapoint in a particular format.

        NOTE: There is an additional remapping function
        because of the support for subsampling the original set
        of trajectories.

        Input:
            idx (int):
                The index of the datapoint that needs to be returned.

        Output:
            datapoint_dict (Dict[str, torch.Tensor]):
                The i-th datapoint in the following dictionary format:
                    {
                        "input_ids": input_id (tensor),
                        "labels": label (tensor),
                        "attention_mask": attention_mask (tensor),
                    }
        """
        remapped_idx = self.indices[idx]
        return super().__getitem__(idx=remapped_idx)


class BanditRWRDataset(MultiturnRWRDataset):
    """
    An special inherited class from Multi-turn RWR dataset.
    This class mostly provides some functionalities to load
    the bandit trajectories and rewards, that are saved in a particular
    format, and then uses the parent classes functionalities
    to perform the rest.
    """

    def __init__(
        self,
        data_dir: str,
        tokenizer: AutoTokenizer,
        tokenizer_separator: TokenizerSeparators,
        ignore_token_id: int,
        gamma: float = 0.9,
        min_reward: float = 0.0,
        num_samples: Optional[int] = None,
    ):
        """
        Input:
            data_dir (str):
                Directory where the bandit trajectories
                are stored as json files.

                This expects the data files in a certain format.

            tokenizer (Tokenizer):
                tokenizer for the model to be trained.

            tokenizer_separator (TokenizerSeparators):
                The tokenizer separator for assistant/user special tokens.

            ignore_token_id (int):
                The token that should be ignored from loss calculations.

            gamma (float):
                Discount factor for the typical RL problem.
                Default: 0.9

            min_reward (float):
                The minimum reward to give for every turn,
                if reward is below this, we clip it.
                Default: 0.0
        """
        bandit_trajectories, bandit_rewards = load_trajectories(data_dir=data_dir)
        super().__init__(
            conversations=bandit_trajectories,
            tokenizer=tokenizer,
            tokenizer_separator=tokenizer_separator,
            ignore_token_id=ignore_token_id,
            reward_per_turns=bandit_rewards,
            gamma=gamma,
            min_reward=min_reward,
        )

        if num_samples is None:
            self.indices = [i for i in range(super().__len__())]
        else:
            if not isinstance(num_samples, int) or num_samples <= 0:
                raise ValueError(f"Given num samples {num_samples} is not valid.")

            self.indices = np.random.choice(
                a=super().__len__(),
                size=num_samples,
                replace=(num_samples > super().__len__()),
            ).tolist()

    def __len__(self) -> int:
        """
        Returns the number of datapoints in the dataset.

        Input:
            None

        Output:
            length: Number of datapoints in the dataset
        """
        return len(self.indices)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        Returns the i-th datapoint in a particular format.

        NOTE: There is an additional remapping function
        because of the support for subsampling the original set
        of trajectories.

        Input:
            idx (int):
                The index of the datapoint that needs to be returned.

        Output:
            datapoint_dict (Dict[str, torch.Tensor]):
                The i-th datapoint in the following dictionary format:
                    {
                        "input_ids": input_id (tensor),
                        "labels": label (tensor),
                        "attention_mask": attention_mask (tensor),
                        "rewards": reward (tensor),
                    }
        """
        remapped_idx = self.indices[idx]
        return super().__getitem__(idx=remapped_idx)


def load_trajectories(
    data_dir: str,
) -> Tuple[List[List[Dict[str, str]]], List[List[Union[float, int]]]]:
    """
    Given a directory containing bandit trajectories
    written in text, stored in json files,
    and makes them ready for the dataset.

    Input:
        data_dir (str):
            directory where the data files are stored.

    Output:
        all_trajectories (List[List[Dict[str, str]]]):
        List of conversations that will be in this dataset.
            [
                [
                    {
                        "role": "user",
                        "content": user_prompt,
                    } ....
                ], # 1st conversation
                [
                    {
                        "role": "user",
                        "content": user_prompt,
                    } ....
                ], # 2nd conversation
                .... (More conversations like this)
            ]

        all_rewards (List[List[Union[float, int]]]):
            all_rewards[i] = the list of rewards obtained at each step
                             for the trajectory all_trajectories[i]
    """
    if not os.path.isdir(data_dir):
        raise ValueError(f"Give data directory {data_dir} is invalid.")

    files = [
        os.path.join(data_dir, file) for file in os.listdir(data_dir) if file.endswith(".json")
    ]
    files = sorted(files)

    all_trajectories = []
    all_rewards = []

    for file in files:
        data = read_json(fname=file)
        if not isinstance(data, dict) or not isinstance(data.get("records"), list):
            raise ValueError(f"Data file is corrupted.")

        for record in data["records"]:
            if not isinstance(record, dict) or not isinstance(
                record.get("conversation"), list
            ):
                raise ValueError(f"Data file is corrupted")

            conversation = record["conversation"]
            for index in range(len(conversation)):
                conversation[index]["content"] = conversation[index]["content"].strip()

            all_trajectories.append(conversation)
            all_rewards.append(record["all_rewards"])

    return all_trajectories, all_rewards
