{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c630412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any, Union, Optional\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from copy import deepcopy\n",
    "import math\n",
    "\n",
    "\n",
    "def measure_cov(data: List[Union[int, float]], cov_type: str) -> np.float64:\n",
    "    \"\"\"\n",
    "    Given a list of integers, measure the co-efficient of variation (COV)\n",
    "    for this list.\n",
    "\n",
    "    Simple estimate:\n",
    "        COV estimate = sample standard deviation / sample mean\n",
    "\n",
    "    Unbiased estimate, assuming distribution of COVs is normal:\n",
    "        COV estimate = (1 + 1/4n) * sample standard deviation / sample mean\n",
    "\n",
    "    Input:\n",
    "        data (List[Union[int, float]]):\n",
    "            List of data points\n",
    "\n",
    "        cov_type (str):\n",
    "            Type of the COV estimator.\n",
    "            Currently supported types: \"simple\" and \"unbiased_normal\"\n",
    "\n",
    "    Output:\n",
    "        cov (np.float64):\n",
    "            Estimate of the co-efficient of variation\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "\n",
    "    if cov_type == \"simple\":\n",
    "        cov = std / mean\n",
    "\n",
    "    elif cov_type == \"unbiased_normal\":\n",
    "        cov = (1.0 + 1.0 / (4 * len(data))) * (std / mean)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Given cov type {cov_type} not supported.\")\n",
    "\n",
    "    return cov\n",
    "\n",
    "\n",
    "def get_statistics_for_already_sampled_data(\n",
    "    alread_sampled_data: Optional[Dict[str, Any]],\n",
    "    cov_type: str,\n",
    "    game_scenario_categories: Dict[str, str],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Given a directory containing collected trajectories,\n",
    "    this function calculates the COVs and trajectories per category.\n",
    "\n",
    "    Input:\n",
    "        data_dir (str):\n",
    "            Directory containing previously collected trajectories,\n",
    "            based on which we will estimate the COVs per category\n",
    "\n",
    "            NOTE: data must be stored in json files, and in the format\n",
    "            that rest of this codebase uses\n",
    "\n",
    "        cov_type (str):\n",
    "            Type of the COV estimator.\n",
    "            Currently supported types: \"simple\" and \"unbiased_normal\"\n",
    "\n",
    "        game_scenario_categories (Dict[str, str]):\n",
    "            A dictionary mapping game scenario (eg., the topic to guess in 20 questions)\n",
    "                to the game category (eg., easy, medium, hard)\n",
    "\n",
    "    Output:\n",
    "        A dictionary of the following format:\n",
    "        {\n",
    "            \"samples_by_category\": samples_by_category,\n",
    "            \"cov_by_category\": cov_by_category,\n",
    "        }\n",
    "\n",
    "        samples_by_category (defaultdict):\n",
    "            A dictionary mapping categories (e.g., easy, medium, hard) to\n",
    "            list of goals sampled for that particular category\n",
    "\n",
    "        cov_by_category (defaultdict):\n",
    "            A dictionary mapping categories (e.g., easy, medium, hard) to\n",
    "            list of covs, where covs are calculated by goals within that category\n",
    "    \"\"\"\n",
    "    cov_by_category = defaultdict(list)\n",
    "    samples_by_category = defaultdict(list)\n",
    "\n",
    "    for record in alread_sampled_data:\n",
    "        num_turn_data = []\n",
    "        scenario = None\n",
    "\n",
    "        # we assume all data within a single record comes from the same scenario\n",
    "        for trial in record:\n",
    "            if scenario is None:\n",
    "                scenario = trial[\"env_game_scenario\"]\n",
    "\n",
    "            # Only take valid data\n",
    "            if trial[\"judge_label\"]:\n",
    "                num_turn_data.append(trial[\"num_turns\"])\n",
    "\n",
    "            else:\n",
    "                num_turn_data.append(trial[\"max_turns\"])\n",
    "\n",
    "        assert scenario is not None\n",
    "\n",
    "        scenario_category = game_scenario_categories[scenario]\n",
    "        samples_by_category[scenario_category].append(scenario)\n",
    "\n",
    "        if len(num_turn_data) > 1:\n",
    "            cov = measure_cov(data=num_turn_data, cov_type=cov_type)\n",
    "            cov_by_category[scenario_category].append(cov)\n",
    "\n",
    "    return {\n",
    "        \"samples_by_category\": samples_by_category,\n",
    "        \"cov_by_category\": cov_by_category,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f62166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load the GameSimulator, so cannot use it!\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from llm_exploration.game import GameEnvironment\n",
    "from llm_exploration.utils.data_utils import read_json, write_json\n",
    "from llm_exploration.utils.torch_utils import set_seed_everywhere\n",
    "\n",
    "\n",
    "def load_data_pool(pool_dir):\n",
    "    all_files = os.listdir(pool_dir)\n",
    "    all_data = {}\n",
    "\n",
    "    for file in all_files:\n",
    "        if file.endswith(\".json\"):\n",
    "            data = read_json(os.path.join(pool_dir, file))\n",
    "\n",
    "            for record in data[\"records\"]:\n",
    "                env_game_scenario = None\n",
    "                for trial in record:\n",
    "                    if env_game_scenario is None:\n",
    "                        env_game_scenario = trial[\"env_game_scenario\"]\n",
    "\n",
    "                    all_data[env_game_scenario] = record\n",
    "                    break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "class Curriculum:\n",
    "    \"\"\"\n",
    "    Base class for our curriculum generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        game_env: GameEnvironment,\n",
    "        game_scenario_categories: Dict[str, str],\n",
    "        game_config: Dict[str, Any],\n",
    "        cov_type: str,\n",
    "        sample_with_replacement: bool,\n",
    "        data_pool_to_sample_from: str,\n",
    "        alpha: float,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            game_env (GameEnvironment):\n",
    "                Particular game environment that we are considering\n",
    "                NOTE: when we move to multiple environments, this may need a code rewrite\n",
    "\n",
    "            game_scenario_categories (Dict[str, str]):\n",
    "                A dictionary mapping game scenario (eg., the topic to guess in 20 questions)\n",
    "                to the game category (eg., easy, medium, hard)\n",
    "\n",
    "            game_config (Dict[str, Any]):\n",
    "                The config for retrieving the data. Usually would contain\n",
    "                \"data_type\" (e.g., train, eval),\n",
    "                and \"data_subtype\" (e.g., \"easy\", \"medium\", \"hard\")\n",
    "\n",
    "            cov_type (str):\n",
    "                The type for the COV estimator. For example, \"simple\" or \"unbiased_normal\"\n",
    "\n",
    "            sample_with_replacement (bool):\n",
    "                Whether to sample the game scenario from the category with replacement or\n",
    "                not.\n",
    "\n",
    "            data_pool_to_sample_from (str):\n",
    "                We collect data from all possible questions first, and sample from this\n",
    "                dataset to simulate online sampling\n",
    "\n",
    "            alpha (float):\n",
    "                Alpha parameter for UCB\n",
    "        \"\"\"\n",
    "        self.game_env = game_env\n",
    "        self.game_scenarios: List[Dict[str, str]] = self.game_env.get_game_scenarios(\n",
    "            config=game_config,\n",
    "        )\n",
    "        self.game_scenario_categories = game_scenario_categories\n",
    "        self.cov_type = cov_type\n",
    "\n",
    "        category_to_scenario_map = defaultdict(set)\n",
    "        game_scenario_to_index_map = {}\n",
    "\n",
    "        for index in range(len(self.game_scenarios)):\n",
    "            scenario = self.game_scenarios[index][\"env\"]\n",
    "            if scenario not in self.game_scenario_categories:\n",
    "                raise ValueError(f\"Given scenario {scenario} not found in category map.\")\n",
    "\n",
    "            scenario_category = self.game_scenario_categories[scenario]\n",
    "            category_to_scenario_map[scenario_category].add(scenario)\n",
    "            game_scenario_to_index_map[scenario] = index\n",
    "\n",
    "        self.category_to_scenario_map = category_to_scenario_map\n",
    "        self.game_scenario_to_index_map = game_scenario_to_index_map\n",
    "        self.sample_with_replacement = sample_with_replacement\n",
    "\n",
    "        self.data_pool = load_data_pool(\n",
    "            pool_dir=data_pool_to_sample_from,\n",
    "        )\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.frequency_of_sampled_category = defaultdict(int)\n",
    "        self.total_reward_of_sampled_category = defaultdict(int)\n",
    "\n",
    "    def print_statistics_of_newly_sampled_data(\n",
    "        self,\n",
    "        chosen_categories_stats: defaultdict,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Helper function to print statistics of the newly sampled batch.\n",
    "        Prints the number of goals sampled per category\n",
    "\n",
    "        Input:\n",
    "            chosen_categories_stats (defaultdict):\n",
    "                A dictionary from category to number of samples in the new batch for\n",
    "                that category\n",
    "\n",
    "        Output:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\"\\nPer Category Chosen Data: \")\n",
    "        for category in chosen_categories_stats:\n",
    "            print(\"Category: \", category, \"Num samples: \", chosen_categories_stats[category])\n",
    "        print()\n",
    "\n",
    "    def generate_next_batch(\n",
    "        self,\n",
    "        curr_samples: Optional[Any],\n",
    "        batch_size: int,\n",
    "        sampling_type: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generates a new batch of topics/game scenarios to generate trajectories from.\n",
    "        Returns the indices of the sampled game scenarios\n",
    "        \"\"\"\n",
    "        assert sampling_type in [\"curriculum\", \"uniform\"]\n",
    "\n",
    "        edges = np.linspace(0, 1, 11)\n",
    "\n",
    "        category_frequencies = {}\n",
    "        total_frequency = 0\n",
    "        for category in self.category_to_scenario_map:\n",
    "            category_frequencies[category] = len(self.category_to_scenario_map[category])\n",
    "            total_frequency += len(self.category_to_scenario_map[category])\n",
    "\n",
    "        for category in self.category_to_scenario_map:\n",
    "            category_frequencies[category] = category_frequencies[category] / total_frequency\n",
    "\n",
    "        sampled_data = []\n",
    "        chosen_categories_stats = defaultdict(int)\n",
    "\n",
    "        if curr_samples is not None:\n",
    "            current_statistics = get_statistics_for_already_sampled_data(\n",
    "                alread_sampled_data=curr_samples,\n",
    "                game_scenario_categories=self.game_scenario_categories,\n",
    "                cov_type=self.cov_type,\n",
    "            )\n",
    "\n",
    "            cov_by_category = current_statistics[\"cov_by_category\"]\n",
    "\n",
    "            for category in cov_by_category:\n",
    "                for cov in cov_by_category[category]:\n",
    "                    self.frequency_of_sampled_category[category] += 1\n",
    "                    self.total_reward_of_sampled_category[category] += cov\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            if sampling_type == \"uniform\":\n",
    "                all_categories = [category for category in self.category_to_scenario_map]\n",
    "                probs = [category_frequencies[category] for category in all_categories]\n",
    "\n",
    "                sampled_category = np.random.choice(\n",
    "                    a=all_categories,\n",
    "                    size=None,\n",
    "                    p=probs,\n",
    "                )\n",
    "                max_category_game_scenarios = list(\n",
    "                    self.category_to_scenario_map[sampled_category]\n",
    "                )\n",
    "                chosen_game_scenario = np.random.choice(\n",
    "                    a=max_category_game_scenarios,\n",
    "                    size=None,\n",
    "                )\n",
    "\n",
    "                chosen_categories_stats[sampled_category] += 1\n",
    "                sampled_data.append(self.data_pool[chosen_game_scenario])\n",
    "\n",
    "            elif sampling_type == \"curriculum\":\n",
    "                category_choices = []\n",
    "                for category in self.category_to_scenario_map:\n",
    "                    if self.frequency_of_sampled_category[category] == 0:\n",
    "                        sample = float(\"inf\")\n",
    "\n",
    "                    else:\n",
    "                        average_reward = (\n",
    "                            self.total_reward_of_sampled_category[category]\n",
    "                            / self.frequency_of_sampled_category[category]\n",
    "                        )\n",
    "                        total_counts = sum(\n",
    "                            [\n",
    "                                self.frequency_of_sampled_category[category]\n",
    "                                for category in self.frequency_of_sampled_category\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                        exploration_bonus = self.alpha * math.sqrt(\n",
    "                            (2 * math.log(total_counts))\n",
    "                            / float(self.frequency_of_sampled_category[category])\n",
    "                        )\n",
    "\n",
    "                        sample = average_reward + exploration_bonus\n",
    "\n",
    "                    category_choices.append((category, sample))\n",
    "\n",
    "                # take the argmax\n",
    "                category_choices = sorted(category_choices, key=lambda x: x[1])\n",
    "\n",
    "                # in case some category is exhausted of samples,\n",
    "                # we pick data from the next best category\n",
    "                most_learnable_category_index = len(category_choices) - 1\n",
    "                found_new_sample = False\n",
    "\n",
    "                if self.sample_with_replacement:\n",
    "                    max_category = category_choices[most_learnable_category_index][0]\n",
    "\n",
    "                    max_category_game_scenarios = list(\n",
    "                        self.category_to_scenario_map[max_category]\n",
    "                    )\n",
    "\n",
    "                    chosen_game_scenario = np.random.choice(\n",
    "                        a=max_category_game_scenarios,\n",
    "                        size=None,\n",
    "                    )\n",
    "                    chosen_categories_stats[max_category] += 1\n",
    "\n",
    "                    sampled_data.append(self.data_pool[chosen_game_scenario])\n",
    "\n",
    "                else:\n",
    "                    while most_learnable_category_index >= 0 and not found_new_sample:\n",
    "                        max_category = category_choices[most_learnable_category_index][0]\n",
    "\n",
    "                        # Choose a sample from the chosen category, uniformly at random\n",
    "                        # that has not been chosen yet\n",
    "                        left_over_game_scenarios = list(\n",
    "                            set(self.category_to_scenario_map[max_category])\n",
    "                            - set(sample_by_category[max_category])\n",
    "                        )\n",
    "\n",
    "                        # we sample from the next most learnable category\n",
    "                        if len(left_over_game_scenarios) == 0:\n",
    "                            most_learnable_category_index -= 1\n",
    "\n",
    "                        else:\n",
    "                            chosen_game_scenario = np.random.choice(\n",
    "                                a=left_over_game_scenarios,\n",
    "                                size=None,\n",
    "                            )\n",
    "\n",
    "                            sample_by_category[max_category].append(chosen_game_scenario)\n",
    "                            sampled_data.append(self.data_pool[chosen_game_scenario])\n",
    "                            chosen_categories_stats[max_category] += 1\n",
    "\n",
    "                            found_new_sample = True\n",
    "\n",
    "                    if not found_new_sample:\n",
    "                        print(\"Dataset is exhausted, can't sample more without replacement.\")\n",
    "                        break\n",
    "\n",
    "        return sampled_data, chosen_categories_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fa95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_online_sampling(\n",
    "    game_env: GameEnvironment,\n",
    "    game_scenario_categories: Dict[str, str],\n",
    "    game_config: Dict[str, Any],\n",
    "    cov_type: str,\n",
    "    sample_with_replacement: bool,\n",
    "    data_pool_to_sample_from: str,\n",
    "    alpha: float,\n",
    "    timesteps: int,\n",
    "    batch_size: int,\n",
    "    sampling_type: str,\n",
    "):\n",
    "    category_frequencies_over_timestep = defaultdict(list)\n",
    "    sampled_data_per_time_step = []\n",
    "\n",
    "    curriculum = Curriculum(\n",
    "        game_env=game_env,\n",
    "        game_scenario_categories=game_scenario_categories,\n",
    "        game_config=game_config,\n",
    "        cov_type=cov_type,\n",
    "        sample_with_replacement=sample_with_replacement,\n",
    "        data_pool_to_sample_from=data_pool_to_sample_from,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "\n",
    "    curr_samples = None\n",
    "\n",
    "    for t in range(timesteps):\n",
    "        (\n",
    "            sampled_data,\n",
    "            chosen_categories_stats,\n",
    "        ) = curriculum.generate_next_batch(\n",
    "            curr_samples=curr_samples,\n",
    "            batch_size=batch_size,\n",
    "            sampling_type=sampling_type,\n",
    "        )\n",
    "\n",
    "        for category in curriculum.category_to_scenario_map:\n",
    "            category_frequencies_over_timestep[category].append(\n",
    "                chosen_categories_stats[category]\n",
    "            )\n",
    "\n",
    "        curr_samples = sampled_data\n",
    "        sampled_data_per_time_step.append(sampled_data)\n",
    "\n",
    "    return category_frequencies_over_timestep, sampled_data_per_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8896a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_exploration.game import get_game_environment\n",
    "\n",
    "\n",
    "def run_one_iteration_of_curriculum(\n",
    "    alpha: float,\n",
    "    batch_size: int,\n",
    "    timesteps: int,\n",
    "    save_file_path: str,\n",
    "    random_seed: int,\n",
    "    sampling_type: str,\n",
    "):\n",
    "    set_seed_everywhere(seed=random_seed)\n",
    "\n",
    "    game_environment = get_game_environment(\n",
    "        environment_name=\"twenty_questions\",\n",
    "    )\n",
    "\n",
    "    game_scenario_categories = read_json(\n",
    "        fname=\"/Users/fahimtajwar/academics/llm_exploration/llm_exploration/curriculum/curriculum_configs/twenty_questions_difficulty_train.json\",\n",
    "    )\n",
    "\n",
    "    game_config = {\n",
    "        \"environment_name\": \"twenty_questions\",\n",
    "        \"data_type\": \"train\",\n",
    "    }\n",
    "\n",
    "    cov_type = \"unbiased_normal\"\n",
    "\n",
    "    data_pool_to_sample_from = \"/Users/fahimtajwar/academics/llm_exploration/exploration_datasets_round_2_curriculum/twenty_questions_datasets/llm_evaluation_on_twenty_questions_split_train_agent_Llama-3.1-8B-Instruct_env_gpt-4o-mini_judge_gpt-4o-mini/curriculum_no_curriculum_round_1\"\n",
    "\n",
    "    category_frequencies_over_timestep, sampled_data_per_time_step = simulate_online_sampling(\n",
    "        game_env=game_environment,\n",
    "        game_scenario_categories=game_scenario_categories,\n",
    "        game_config=game_config,\n",
    "        cov_type=cov_type,\n",
    "        sample_with_replacement=True,\n",
    "        data_pool_to_sample_from=data_pool_to_sample_from,\n",
    "        alpha=alpha,\n",
    "        timesteps=timesteps,\n",
    "        batch_size=batch_size,\n",
    "        sampling_type=sampling_type,\n",
    "    )\n",
    "\n",
    "    for t in range(3):\n",
    "        data = sampled_data_per_time_step[t]\n",
    "\n",
    "        all_topics = []\n",
    "        for d in data:\n",
    "            all_topics.append(d[0][\"env_game_scenario\"])\n",
    "\n",
    "    for category in category_frequencies_over_timestep:\n",
    "        print(\n",
    "            \"Category: \",\n",
    "            category,\n",
    "            \"total: \",\n",
    "            sum(category_frequencies_over_timestep[category]),\n",
    "        )\n",
    "\n",
    "    print(category_frequencies_over_timestep)\n",
    "\n",
    "    all_data = []\n",
    "    for t in range(timesteps):\n",
    "        data_t = sampled_data_per_time_step[t]\n",
    "\n",
    "        for data in data_t:\n",
    "            all_data.append(data)\n",
    "\n",
    "    write_json(\n",
    "        data={\"records\": all_data},\n",
    "        fname=save_file_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda17e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  medium total:  119\n",
      "Category:  easy total:  79\n",
      "Category:  hard total:  52\n",
      "defaultdict(<class 'list'>, {'medium': [1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1], 'easy': [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'hard': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]})\n"
     ]
    }
   ],
   "source": [
    "run_one_iteration_of_curriculum(\n",
    "    alpha=1.0,\n",
    "    batch_size=1,\n",
    "    timesteps=250,\n",
    "    save_file_path=\"/Users/fahimtajwar/academics/llm_exploration/exploration_datasets_train_curriculum/uniform_round_3_seed_71/data.json\",\n",
    "    random_seed=71,\n",
    "    sampling_type=\"uniform\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8066f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
